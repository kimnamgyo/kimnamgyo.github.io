---
layout: single
title:  "타이타닉 관련 모델 훈련 과정"
categories: coding
tag: [python, blog, jekyll]
toc: true
author_profile: false
---

<head>
  <style>
    table.dataframe {
      white-space: normal;
      width: 100%;
      height: 240px;
      display: block;
      overflow: auto;
      font-family: Arial, sans-serif;
      font-size: 0.9rem;
      line-height: 20px;
      text-align: center;
      border: 0px !important;
    }

    table.dataframe th {
      text-align: center;
      font-weight: bold;
      padding: 8px;
    }

    table.dataframe td {
      text-align: center;
      padding: 8px;
    }

    table.dataframe tr:hover {
      background: #b8d1f3; 
    }

    .output_prompt {
      overflow: auto;
      font-size: 0.9rem;
      line-height: 1.45;
      border-radius: 0.3rem;
      -webkit-overflow-scrolling: touch;
      padding: 0.8rem;
      margin-top: 0;
      margin-bottom: 15px;
      font: 1rem Consolas, "Liberation Mono", Menlo, Courier, monospace;
      color: $code-text-color;
      border: solid 1px $border-color;
      border-radius: 0.3rem;
      word-break: normal;
      white-space: pre;
    }

  .dataframe tbody tr th:only-of-type {
      vertical-align: middle;
  }

  .dataframe tbody tr th {
      vertical-align: top;
  }

  .dataframe thead th {
      text-align: center !important;
      padding: 8px;
  }

  .page__content p {
      margin: 0 0 0px !important;
  }

  .page__content p > strong {
    font-size: 0.8rem !important;
  }

  </style>
</head>


###  Tackle the Titanic dataset



연습: _타이타닉 데이터 세트를 처리합니다. 시작하기에 좋은 장소는 [Kaggle](https://www.kaggle.com/c/titanic)입니다. 또는 https://homl.info/titanic.tgz 에서 데이터를 다운로드하여 2장의 하우징 데이터에 대해 했던 것처럼 이 tarball의 압축을 풀 수 있습니다. 그러면 두 개의 CSV 파일 _train.csv_와 _test.csv_가 제공됩니다. 이 파일은 'pandas.read_csv()lindo'를 사용하여 로드할 수 있습니다. 목표는 다른 열을 기반으로 "생존" 열을 예측할 수 있는 분류기를 훈련시키는 것입니다._



```python
from pathlib import Path
import pandas as pd
import tarfile
import urllib.request

def load_titanic_data():
    tarball_path = Path("datasets/titanic.tgz")
    if not tarball_path.is_file():
        Path("datasets").mkdir(parents=True, exist_ok=True)
        url = "https://github.com/ageron/data/raw/main/titanic.tgz"
        urllib.request.urlretrieve(url, tarball_path)
        with tarfile.open(tarball_path) as titanic_tarball:
            titanic_tarball.extractall(path="datasets")
    return [pd.read_csv(Path("datasets/titanic") / filename)
            for filename in ("train.csv", "test.csv")]
```


```python
train_data, test_data = load_titanic_data()
```

데이터가 이미 교육 세트와 테스트 세트로 분할되어 있습니다. 그러나 테스트 데이터에는 레이블이 *포함되지* 않습니다. 교육 데이터를 사용하여 최상의 모델을 교육한 다음 테스트 데이터에 대한 예측을 하고 Kaggle에 업로드하여 최종 점수를 확인하는 것이 목표입니다.


교육 세트의 상위 몇 줄을 살펴보겠습니다:



```python
train_data.head()
```

<pre>
   PassengerId  Survived  Pclass  \
0            1         0       3   
1            2         1       1   
2            3         1       3   
3            4         1       1   
4            5         0       3   

                                                Name     Sex   Age  SibSp  \
0                            Braund, Mr. Owen Harris    male  22.0      1   
1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   
2                             Heikkinen, Miss. Laina  female  26.0      0   
3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   
4                           Allen, Mr. William Henry    male  35.0      0   

   Parch            Ticket     Fare Cabin Embarked  
0      0         A/5 21171   7.2500   NaN        S  
1      0          PC 17599  71.2833   C85        C  
2      0  STON/O2. 3101282   7.9250   NaN        S  
3      0            113803  53.1000  C123        S  
4      0            373450   8.0500   NaN        S  
</pre>
속성의 의미는 다음과 같습니다:

* **PassengerId**: 각 승객의 고유 식별자

* **Survived**: 그것이 목표입니다. 0은 승객이 살아남지 못했다는 것을 의미하고, 1은 승객이 살아남았다는 것을 의미합니다.

* **Pclass**: 승객 클래스.

* **Name**, **Sex**, **Age**: 자기설명

* **SibSp**: 타이타닉에 탑승한 승객의 형제자매와 배우자 수.

* **Parch**: 타이타닉에 탑승한 승객의 자녀와 부모 수.

* **Ticket**: 티켓 ID

* **Fare**: 지불된 가격(파운드)

* **Cabin**: 승객 객실 번호

* **Embarked**: 승객이 타이타닉에 탑승한 장소


목표는 승객의 나이, 성별, 승객 등급, 탑승 장소 등의 속성을 기반으로 승객의 생존 여부를 예측하는 것입니다.


'PassengerId' 열을 인덱스 열로 명시적으로 설정합니다



```python
train_data = train_data.set_index("PassengerId")
test_data = test_data.set_index("PassengerId")
```

누락된 데이터의 양을 확인하려면 다음과 같이 하십시오



```python
train_data.info()
```

<pre>
<class 'pandas.core.frame.DataFrame'>
Int64Index: 891 entries, 1 to 891
Data columns (total 11 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Survived  891 non-null    int64  
 1   Pclass    891 non-null    int64  
 2   Name      891 non-null    object 
 3   Sex       891 non-null    object 
 4   Age       714 non-null    float64
 5   SibSp     891 non-null    int64  
 6   Parch     891 non-null    int64  
 7   Ticket    891 non-null    object 
 8   Fare      891 non-null    float64
 9   Cabin     204 non-null    object 
 10  Embarked  889 non-null    object 
dtypes: float64(2), int64(4), object(5)
memory usage: 83.5+ KB
</pre>

```python
train_data[train_data["Sex"]=="female"]["Age"].median()
```

<pre>
27.0
</pre>
**Age**, **Cabin** 및 **Embarked** 특성은 때때로 null(891개 미만의 null)이며, 특히 **Cabin**(77%가 null)입니다. 우리는 지금은 **Cabin**을 무시하고 나머지에 집중할 것입니다. **Age** 특성의 null 값은 약 19%이므로 이 값으로 수행할 작업을 결정해야 합니다. null 값을 중위수 연령으로 대체하는 것이 합리적인 것 같습니다. 다른 열을 기준으로 나이를 예측하면 조금 더 현명해질 수 있습니다(예: 중위 연령은 1등 37세, 2등 29세, 3등 24세). 하지만 우리는 단순하게 유지하고 전체 중위 연령을 사용할 것입니다.


**Name** 및 **Ticket** 속성은 일부 값을 가질 수 있지만 모델이 사용할 수 있는 유용한 숫자로 변환하기가 다소 까다로울 수 있습니다. 그래서 지금은, 우리는 그들을 무시할 것입니다.


수치 속성을 살펴보겠습니다:



```python
train_data.describe()
```

<pre>
         Survived      Pclass         Age       SibSp       Parch        Fare
count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000
mean     0.383838    2.308642   29.699113    0.523008    0.381594   32.204208
std      0.486592    0.836071   14.526507    1.102743    0.806057   49.693429
min      0.000000    1.000000    0.416700    0.000000    0.000000    0.000000
25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400
50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200
75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000
max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200
</pre>
* 단 38%만이 **Survived**되었습니다. 이는 40%에 충분히 가깝기 때문에 정확도는 모델을 평가하는 데 합리적인 측정 기준이 될 것입니다.

* 평균 **Fare**는 £32.20으로, 그렇게 비싸지는 않은 것 같습니다(그러나 그 당시에는 아마도 큰 돈이었을 것입니다).

* 평균 **Age**는 30세 미만이었습니다.


목표값이 실제로 0 또는 1인지 확인합니다:



```python
train_data["Survived"].value_counts()
```

<pre>
0    549
1    342
Name: Survived, dtype: int64
</pre>

```python
train_data["Pclass"].value_counts()
```

<pre>
3    491
1    216
2    184
Name: Pclass, dtype: int64
</pre>

```python
train_data["Sex"].value_counts()
```

<pre>
male      577
female    314
Name: Sex, dtype: int64
</pre>

```python
train_data["Embarked"].value_counts()
```

<pre>
S    644
C    168
Q     77
Name: Embarked, dtype: int64
</pre>
Jagained 속성은 승객이 탑승한 위치를 알려줍니다. C=Cherbourg, Q=Queensstown, S=Southampton.


이제 수치 속성을 위한 파이프라인부터 시작하여 전처리 파이프라인을 구축해 보겠습니다:



```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

num_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler())
    ])
```

이제 범주형 특성을 위한 파이프라인을 구축할 수 있습니다:



```python
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
```


```python
cat_pipeline = Pipeline([
        ("ordinal_encoder", OrdinalEncoder()),    
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("cat_encoder", OneHotEncoder(sparse=False)),
    ])
```

마지막으로, 수치 및 범주형 파이프라인을 만들어 보겠습니다:



```python
from sklearn.compose import ColumnTransformer

num_attribs = ["Age", "SibSp", "Parch", "Fare"]
cat_attribs = ["Pclass", "Sex", "Embarked"]

preprocess_pipeline = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", cat_pipeline, cat_attribs),
    ])
```

이제 원시 데이터를 가져와서 원하는 모든 기계 학습 모델에 제공할 수 있는 수치 입력 기능을 출력하는 훌륭한 전처리 파이프라인이 있습니다.



```python
X_train = preprocess_pipeline.fit_transform(train_data)
X_train
```

<pre>
/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
</pre>
<pre>
array([[-0.56573582,  0.43279337, -0.47367361, ...,  0.        ,
         0.        ,  1.        ],
       [ 0.6638609 ,  0.43279337, -0.47367361, ...,  1.        ,
         0.        ,  0.        ],
       [-0.25833664, -0.4745452 , -0.47367361, ...,  0.        ,
         0.        ,  1.        ],
       ...,
       [-0.10463705,  0.43279337,  2.00893337, ...,  0.        ,
         0.        ,  1.        ],
       [-0.25833664, -0.4745452 , -0.47367361, ...,  1.        ,
         0.        ,  0.        ],
       [ 0.20276213, -0.4745452 , -0.47367361, ...,  0.        ,
         1.        ,  0.        ]])
</pre>

```python
y_train = train_data["Survived"]
```

이제 분류자를 교육할 준비가 되었습니다. "랜덤 포레스트 분류기"로 시작하겠습니다:



```python
from sklearn.ensemble import RandomForestClassifier

forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)
forest_clf.fit(X_train, y_train)
```

<pre>
RandomForestClassifier(random_state=42)
</pre>
이 모델은 교육을 받은 모델입니다. 이를 사용하여 테스트 세트에 대한 예측을 해 보겠습니다:



```python
X_test = preprocess_pipeline.transform(test_data)
y_pred = forest_clf.predict(X_test)
```

이제 이러한 예측(Kaggle이 제외한 형식)을 사용하여 CSV 파일을 구축한 다음 업로드하여 최상의 결과를 기대할 수 있습니다. 하지만 잠깐! 우리는 희망보다 더 잘 할 수 있습니다. 교차 검증을 사용하여 모델이 얼마나 우수한지 파악해 보는 것은 어떨까요?



```python
from sklearn.model_selection import cross_val_score

forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)
forest_scores.mean()
```

<pre>
0.8137578027465668
</pre>
Kaggle에서 열리는 타이타닉 대회의 [리더보드](https://www.kaggle.com/c/titanic/leaderboard)를 보면, 우리의 점수가 상위 2%에 있다는 것을 알 수 있습니다. 일부 카글러들은 100% 정확도에 도달했지만, 여러분은 [타이타닉의 희생자 목록](https://www.encyclopedia-titanica.org/titanic-victims/)을 쉽게 찾을 수 있기 때문에, 그들의 성능에 기계 학습이 거의 개입되지 않았을 가능성이 높습니다.


SVC를 사용해 보겠습니다:



```python
from sklearn.svm import SVC

svm_clf = SVC(gamma="auto")
svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)
svm_scores.mean()
```

<pre>
0.8249313358302123
</pre>
그러나 10개의 교차 검증 접기에서 평균 정확도를 확인하는 대신, 각 모델에 대한 10개의 모든 점수를 하위 및 상위 사분위수를 강조하는 상자 그림과 점수의 범위를 보여주는 "whiskers"와 함께 표시합니다(이 시각화를 제안한 Nevin Yilmaz 덕분). 'boxplot()' 함수는 특이치("플라이어"라고 함)를 감지하며  whiskers에는 포함되지 않습니다. 특히, 하위 사분위수가 $Q_1$이고 상위 사분위수가 $Q_3$이면, 사분위수 범위 $IQR = Q_3 - Q_1$(이것은 상자 높이)이며, $Q_1 - 1.5 \times IQR$보다 낮은 점수는 플라이어이며, $Q3 + 1.5 \times IQR$보다 큰 점수도 마찬가지입니다.



```python
import matplotlib.pyplot as plt

plt.rc('font', size=14)
plt.rc('axes', labelsize=14, titlesize=14)
plt.rc('legend', fontsize=14)
plt.rc('xtick', labelsize=10)
plt.rc('ytick', labelsize=10)

plt.figure(figsize=(8, 4))
plt.plot([1]*10, svm_scores, ".")
plt.plot([2]*10, forest_scores, ".")
plt.boxplot([svm_scores, forest_scores], labels=("SVM", "Random Forest"))
plt.ylabel("Accuracy")
plt.show()
```

<pre>
<Figure size 800x400 with 1 Axes>
</pre>
랜덤 포레스트 분류기는 10개의 접힌 부분 중 하나에서 매우 높은 점수를 받았지만 전체적으로 평균 점수가 낮고 확산도 커 SVM 분류기가 일반화될 가능성이 더 높은 것으로 보입니다.


이 결과를 더욱 개선하기 위해 다음을 수행할 수 있습니다:

* 교차 검증 및 그리드 검색을 사용하여 더 많은 모델을 비교하고 하이퍼 파라미터를 조정합니다,

* 다음과 같이 피쳐 엔지니어링을 더 수행합니다:

* 숫자 속성을 범주형 속성으로 변환해 보십시오. 예를 들어, 연령 그룹에 따라 생존율이 매우 다르므로(아래 참조) 연령 버킷 범주를 만들어 연령 대신 사용하는 것이 도움이 될 수 있습니다. 마찬가지로, 30%만 생존했기 때문에 혼자 여행하는 사람들을 위한 특별한 범주를 갖는 것이 유용할 수 있습니다(아래 참조).

* **SibSp** 및 **Parch**를 합으로 바꿉니다.

* **Survived** 특성과 잘 연관된 이름 부분을 식별합니다.

* **cabin** 열을 사용합니다. 예를 들어, 첫 번째 문자를 사용하여 범주형 속성으로 처리합니다.



```python
train_data["AgeBucket"] = train_data["Age"] // 15 * 15
train_data[["AgeBucket", "Survived"]].groupby(['AgeBucket']).mean()
```

<pre>
           Survived
AgeBucket          
0.0        0.576923
15.0       0.362745
30.0       0.423256
45.0       0.404494
60.0       0.240000
75.0       1.000000
</pre>

```python
train_data["RelativesOnboard"] = train_data["SibSp"] + train_data["Parch"]
train_data[["RelativesOnboard", "Survived"]].groupby(
    ['RelativesOnboard']).mean()
```

<pre>
                  Survived
RelativesOnboard          
0                 0.303538
1                 0.552795
2                 0.578431
3                 0.724138
4                 0.200000
5                 0.136364
6                 0.333333
7                 0.000000
10                0.000000
</pre>